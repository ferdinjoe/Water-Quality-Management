{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6CQqY1dLlgT"
   },
   "source": [
    "#Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1639670689765,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "89khZ_mH711c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1639670693953,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "HIbQbjduS_FA",
    "outputId": "cea0c5a4-bfdb-42df-ddc0-a855d15c99b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>UTC Hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10_mask</th>\n",
       "      <th>Retrospective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>62.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>62.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>47.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40236</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40237</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40238</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40239</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40240</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40241 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  Day  UTC Hour  PM2.5  PM10_mask  Retrospective\n",
       "0      2016      3    3         8   62.9        1.0              0\n",
       "1      2016      3    3         9   62.9        1.0              0\n",
       "2      2016      3    3        10   55.5        1.0              0\n",
       "3      2016      3    3        11   55.5        1.0              0\n",
       "4      2016      3    3        12   47.9        1.0              0\n",
       "...     ...    ...  ...       ...    ...        ...            ...\n",
       "40236  2021      6    1        16   15.6        0.0              0\n",
       "40237  2021      6    1        16   15.6        0.0              0\n",
       "40238  2021      6    1        16   15.6        0.0              0\n",
       "40239  2021      6    1        16   15.6        0.0              0\n",
       "40240  2021      6    1        16   15.6        0.0              0\n",
       "\n",
       "[40241 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Bangkok.txt', sep = \"\\t\", names = ['Year', 'Month', 'Day', 'UTC Hour', 'PM2.5', 'PM10_mask', 'Retrospective'] ,header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1639670693954,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "qGkopmBx8LYJ"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/drive/MyDrive/PM2.5 Project/Samut_Sakhon.txt', sep = \"\\t\", names = ['Year', 'Month', 'Day', 'UTC Hour', 'PM2.5', 'PM10_mask', 'Retrospective'] ,header=None)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1639670693955,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "KUc-ZUE-_XMC",
    "outputId": "c769a276-86ee-433b-ec53-b60208acc3d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>UTC Hour</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40236</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40237</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40238</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40239</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40240</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40241 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  Day  UTC Hour  PM2.5\n",
       "0      2016      3    3         8   62.9\n",
       "1      2016      3    3         9   62.9\n",
       "2      2016      3    3        10   55.5\n",
       "3      2016      3    3        11   55.5\n",
       "4      2016      3    3        12   47.9\n",
       "...     ...    ...  ...       ...    ...\n",
       "40236  2021      6    1        16   15.6\n",
       "40237  2021      6    1        16   15.6\n",
       "40238  2021      6    1        16   15.6\n",
       "40239  2021      6    1        16   15.6\n",
       "40240  2021      6    1        16   15.6\n",
       "\n",
       "[40241 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['PM10_mask', 'Retrospective'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1639670693955,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "fy2uKrJkBZbe",
    "outputId": "2761aa01-bc6f-44cd-ac68-ae4def5e8f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'UTC Hour', 'PM2.5'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt2UGwXbLwbf"
   },
   "source": [
    "#Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1639670693955,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "dySgSnjABfrK"
   },
   "outputs": [],
   "source": [
    "# split a dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1639670693956,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "tjjmfySNB-bv"
   },
   "outputs": [],
   "source": [
    "y = data['PM2.5']\n",
    "X = data[['Year', 'Month', 'Day', 'UTC Hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1639670693956,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "0C1zxXJ9Bt9s",
    "outputId": "ee22b29e-8f4b-4662-f568-6bc940be0afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32192, 4) (8049, 4) (32192,) (8049,)\n"
     ]
    }
   ],
   "source": [
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1639670693957,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "SfImZQMmFtXk",
    "outputId": "e03df9c2-c243-4082-e43b-5bd93e9d291e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Year  Month  Day  UTC Hour\n",
       "6778   2016     12   26        16\n",
       "30910  2020      2   17         0\n",
       "18356  2018      6   12        17\n",
       "20446  2018      9   11        16\n",
       "20187  2018      8   31         2\n",
       "...     ...    ...  ...       ...\n",
       "8644   2017      3   24        11\n",
       "21773  2018     11    8         0\n",
       "21918  2018     11   14         6\n",
       "33405  2020      6    3         0\n",
       "8612   2017      3   23         3\n",
       "\n",
       "[32192 rows x 4 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1639670694815,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "FDdAPizd3oU4",
    "outputId": "de5ce412-b34e-4af3-96fd-c49c33280f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 6778     52.9\n",
       "30910    19.2\n",
       "18356    11.4\n",
       "20446    19.3\n",
       "20187    17.2\n",
       "         ... \n",
       "8644     11.8\n",
       "21773    24.6\n",
       "21918    35.9\n",
       "33405     9.1\n",
       "8612     24.5\n",
       "Name: PM2.5, Length: 32192, dtype: float64>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1639670694815,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "WiKoqV0062Jn",
    "outputId": "8b4c1a06-4922-48f7-ebeb-413241bfa872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32192, 4)\n",
      "y_train shape: (32192,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1639670694816,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "qRgkCz3MAj13",
    "outputId": "bc58789e-897b-474a-a97b-3193e50d631c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month  Day  UTC Hour\n",
      "6778   2016     12   26        16\n",
      "30910  2020      2   17         0\n",
      "18356  2018      6   12        17\n",
      "20446  2018      9   11        16\n",
      "20187  2018      8   31         2\n",
      "...     ...    ...  ...       ...\n",
      "8644   2017      3   24        11\n",
      "21773  2018     11    8         0\n",
      "21918  2018     11   14         6\n",
      "33405  2020      6    3         0\n",
      "8612   2017      3   23         3\n",
      "\n",
      "[32192 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1639670694816,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "iGp0g5EwGWiX"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1639670694817,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Yy0HMRwQDYJ8"
   },
   "outputs": [],
   "source": [
    "n_steps = 1\n",
    "n_features = 4\n",
    "b_size = 100\n",
    "look_back = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1639670694817,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "QKct5E-uC0AI"
   },
   "outputs": [],
   "source": [
    "def trim_data(data, batch_size):\n",
    "  \"\"\"\n",
    "  Trims out the extra data that does not fit into batches\n",
    "  EX:\n",
    "  dim, batch_size = 192, 50\n",
    "  to\n",
    "  dim, batch_size = 150, 50\n",
    "\n",
    "  PARAMETERS\n",
    "  ----------\n",
    "  data: ndarray\n",
    "    The data that you want to trim\n",
    "  batch_size: int\n",
    "    The batch size\n",
    "  \"\"\"\n",
    "  extra = data.shape[0] % batch_size\n",
    "  if (extra == 0):\n",
    "    return data\n",
    "  return data[:-extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1639670694817,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "_d7FZnYoEPPK"
   },
   "outputs": [],
   "source": [
    "X_train = trim_data(X_train, b_size)\n",
    "y_train = trim_data(y_train, b_size)\n",
    "X_test  = trim_data(X_test, b_size)\n",
    "y_test  = trim_data(y_test, b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1639670694817,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "gFJUWarmEdm2"
   },
   "outputs": [],
   "source": [
    "assert X_train.shape[0] == y_train.shape[0], \"Train dimension mismatch\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Test dimension mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1639670694817,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "NgOSSMS7AonX",
    "outputId": "7b8c45de-bce5-4c8f-87f2-7319c24d2444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2016   12   26   16]\n",
      " [2020    2   17    0]\n",
      " [2018    6   12   17]\n",
      " ...\n",
      " [2018    1    6    8]\n",
      " [2021    6    1   16]\n",
      " [2017    8   15   21]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1639670694818,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "MO1LnN-Q3s9n",
    "outputId": "5eee6fd4-c3a6-429d-c509-83057684d141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32100, 4) (8000, 4) (32100,) (8000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1639670694819,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "bIYzCFis_u4_"
   },
   "outputs": [],
   "source": [
    "X_train_len = X_train.shape[0]\n",
    "X_test_len = X_test.shape[0]\n",
    "y_train_len = y_train.shape[0]\n",
    "y_test_len = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1639670694819,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "5G04ymCv_8VM"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train_len, n_steps, n_features)\n",
    "X_test  = X_test.reshape(X_test_len, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1639670694820,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "fPe_b3n6APio",
    "outputId": "c41c8fd0-9bad-4040-fbce-6565e0a13836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2016   12   26   16]]\n",
      "\n",
      " [[2020    2   17    0]]\n",
      "\n",
      " [[2018    6   12   17]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2018    1    6    8]]\n",
      "\n",
      " [[2021    6    1   16]]\n",
      "\n",
      " [[2017    8   15   21]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvdZo5kbL0PU"
   },
   "source": [
    "#Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1639670694820,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "w6_PQBDuCZlS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, LSTM, Bidirectional, RepeatVector, TimeDistributed, Input, Flatten, Dropout, InputLayer\n",
    "from keras.layers import LSTM, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyUjsZEcf68n"
   },
   "source": [
    "##Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1639670694820,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "cvQBUTBTCnAo"
   },
   "outputs": [],
   "source": [
    "###Basic LSTM###\n",
    "basic_model = Sequential()\n",
    "basic_model.add(LSTM(200, batch_input_shape=(b_size, n_steps, n_features), name=\"LSTMLayer\"))\n",
    "basic_model.add(Dense(1, name=\"OutputLayer\"))\n",
    "basic_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32997,
     "status": "error",
     "timestamp": 1639670727804,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "NRdnokYmyGj7",
    "outputId": "92b33881-12f8-4f66-be18-a302b3d45b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDA7B59168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDA7B59168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 2s 2ms/step - loss: 453.7155 - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 237.4592 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 188.4109 - accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.3409 - accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9756 - accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9758 - accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 181.7425 - accuracy: 0.0000e+ - 1s 2ms/step - loss: 181.9784 - accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9789 - accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9812 - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9793 - accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9819 - accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9887 - accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9769 - accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9838 - accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9830 - accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9850 - accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9859 - accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0189 - accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9939 - accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9852 - accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9850 - accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9910 - accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9923 - accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0001 - accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0125 - accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9872 - accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9843 - accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9887 - accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9811 - accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0247 - accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9894 - accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9967 - accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9948 - accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9875 - accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9905 - accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9845 - accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9810 - accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0224 - accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9944 - accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0039 - accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9987 - accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0047 - accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9966 - accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9503 - accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9844 - accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0015 - accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0205 - accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9905 - accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9856 - accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0109 - accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9926 - accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0012 - accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9559 - accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0093 - accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9875 - accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9967 - accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9808 - accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0079 - accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0209 - accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9969 - accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9624 - accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9901 - accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9863 - accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0155 - accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9811 - accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0097 - accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9965 - accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0145 - accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9882 - accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9880 - accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9950 - accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0054 - accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0095 - accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0031 - accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0209 - accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9999 - accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9880 - accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9847 - accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9869 - accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0057 - accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9862 - accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9995 - accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0045 - accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9983 - accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9872 - accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9883 - accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9928 - accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9924 - accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9977 - accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9994 - accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0007 - accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9857 - accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9875 - accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9959 - accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0094 - accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0109 - accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9769 - accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0238 - accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0081 - accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9913 - accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0154 - accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0061 - accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0006 - accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9864 - accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0177 - accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9950 - accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9644 - accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9762 - accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0234 - accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0199 - accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0002 - accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9830 - accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0257 - accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9860 - accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0052 - accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9924 - accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9997 - accuracy: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9819 - accuracy: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9918 - accuracy: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9893 - accuracy: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9960 - accuracy: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9849 - accuracy: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9940 - accuracy: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9965 - accuracy: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9861 - accuracy: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0041 - accuracy: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0130 - accuracy: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9906 - accuracy: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9863 - accuracy: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9971 - accuracy: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9948 - accuracy: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9865 - accuracy: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0101 - accuracy: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0097 - accuracy: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9830 - accuracy: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0011 - accuracy: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9683 - accuracy: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9886 - accuracy: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9823 - accuracy: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0057 - accuracy: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9951 - accuracy: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0185 - accuracy: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9979 - accuracy: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9793 - accuracy: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9996 - accuracy: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0046 - accuracy: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0227 - accuracy: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9992 - accuracy: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9830 - accuracy: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0177 - accuracy: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0107 - accuracy: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0113 - accuracy: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9951 - accuracy: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0128 - accuracy: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0007 - accuracy: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0024 - accuracy: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9940 - accuracy: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9767 - accuracy: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0077 - accuracy: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9881 - accuracy: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9918 - accuracy: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0151 - accuracy: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0068 - accuracy: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9912 - accuracy: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0141 - accuracy: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0074 - accuracy: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0076 - accuracy: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9892 - accuracy: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0223 - accuracy: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0172 - accuracy: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9784 - accuracy: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9778 - accuracy: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9874 - accuracy: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9777 - accuracy: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0030 - accuracy: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9767 - accuracy: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9894 - accuracy: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9904 - accuracy: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9809 - accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9848 - accuracy: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0099 - accuracy: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9954 - accuracy: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9826 - accuracy: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0082 - accuracy: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9545 - accuracy: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9971 - accuracy: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0117 - accuracy: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0158 - accuracy: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9945 - accuracy: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0275 - accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9773 - accuracy: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9906 - accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9974 - accuracy: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0038 - accuracy: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0004 - accuracy: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9924 - accuracy: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9999 - accuracy: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9934 - accuracy: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9726 - accuracy: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9770 - accuracy: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0022 - accuracy: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0121 - accuracy: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0019 - accuracy: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9988 - accuracy: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0113 - accuracy: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9901 - accuracy: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0153 - accuracy: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0031 - accuracy: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9848 - accuracy: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0032 - accuracy: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9915 - accuracy: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9857 - accuracy: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9856 - accuracy: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0056 - accuracy: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9845 - accuracy: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9996 - accuracy: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9745 - accuracy: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9866 - accuracy: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0100 - accuracy: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0082 - accuracy: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9901 - accuracy: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9854 - accuracy: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9845 - accuracy: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0119 - accuracy: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0016 - accuracy: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9945 - accuracy: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0124 - accuracy: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0064 - accuracy: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9910 - accuracy: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9808 - accuracy: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9949 - accuracy: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0180 - accuracy: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9851 - accuracy: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0158 - accuracy: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0300 - accuracy: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0155 - accuracy: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9842 - accuracy: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0048 - accuracy: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0106 - accuracy: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9996 - accuracy: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0032 - accuracy: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0048 - accuracy: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0041 - accuracy: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0065 - accuracy: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9943 - accuracy: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9887 - accuracy: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0039 - accuracy: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0215 - accuracy: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0141 - accuracy: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9834 - accuracy: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9852 - accuracy: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0152 - accuracy: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0022 - accuracy: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9841 - accuracy: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0071 - accuracy: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9893 - accuracy: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0022 - accuracy: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0030 - accuracy: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9850 - accuracy: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0152 - accuracy: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0045 - accuracy: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9756 - accuracy: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0088 - accuracy: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9789 - accuracy: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0091 - accuracy: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0200 - accuracy: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0141 - accuracy: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0019 - accuracy: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9841 - accuracy: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0373 - accuracy: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9924 - accuracy: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0137 - accuracy: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0347 - accuracy: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0278 - accuracy: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9852 - accuracy: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9944 - accuracy: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0066 - accuracy: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0035 - accuracy: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0021 - accuracy: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0067 - accuracy: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9825 - accuracy: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9855 - accuracy: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0222 - accuracy: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0019 - accuracy: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9658 - accuracy: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9732 - accuracy: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0017 - accuracy: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0046 - accuracy: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9903 - accuracy: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9896 - accuracy: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9934 - accuracy: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0054 - accuracy: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9902 - accuracy: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0087 - accuracy: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9986 - accuracy: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9985 - accuracy: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9905 - accuracy: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9806 - accuracy: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0144 - accuracy: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0155 - accuracy: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0006 - accuracy: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9924 - accuracy: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9824 - accuracy: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9870 - accuracy: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9927 - accuracy: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0103 - accuracy: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9977 - accuracy: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0059 - accuracy: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0062 - accuracy: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9859 - accuracy: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0044 - accuracy: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9934 - accuracy: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9490 - accuracy: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0380 - accuracy: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9879 - accuracy: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0119 - accuracy: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0042 - accuracy: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0107 - accuracy: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0046 - accuracy: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0033 - accuracy: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9844 - accuracy: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9763 - accuracy: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9755 - accuracy: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0177 - accuracy: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0137 - accuracy: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9864 - accuracy: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0095 - accuracy: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0045 - accuracy: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0034 - accuracy: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9936 - accuracy: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0120 - accuracy: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9876 - accuracy: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9959 - accuracy: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9884 - accuracy: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9963 - accuracy: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9847 - accuracy: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0042 - accuracy: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9633 - accuracy: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9900 - accuracy: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0007 - accuracy: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9810 - accuracy: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0017 - accuracy: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0018 - accuracy: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0093 - accuracy: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9813 - accuracy: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0005 - accuracy: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9931 - accuracy: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9828 - accuracy: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9991 - accuracy: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0007 - accuracy: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9936 - accuracy: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9878 - accuracy: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9983 - accuracy: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9796 - accuracy: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9925 - accuracy: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9986 - accuracy: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9681 - accuracy: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9910 - accuracy: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0069 - accuracy: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9741 - accuracy: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9940 - accuracy: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0166 - accuracy: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9920 - accuracy: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9968 - accuracy: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9916 - accuracy: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0015 - accuracy: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0036 - accuracy: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0072 - accuracy: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0001 - accuracy: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9991 - accuracy: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9939 - accuracy: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0082 - accuracy: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9795 - accuracy: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9889 - accuracy: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0002 - accuracy: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0075 - accuracy: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9909 - accuracy: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0166 - accuracy: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9845 - accuracy: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9954 - accuracy: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9971 - accuracy: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0012 - accuracy: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9965 - accuracy: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0147 - accuracy: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9967 - accuracy: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0004 - accuracy: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9965 - accuracy: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0063 - accuracy: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0005 - accuracy: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9925 - accuracy: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0045 - accuracy: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9698 - accuracy: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9971 - accuracy: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0042 - accuracy: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0181 - accuracy: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0033 - accuracy: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0014 - accuracy: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0102 - accuracy: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9977 - accuracy: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9931 - accuracy: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0038 - accuracy: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9967 - accuracy: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9366 - accuracy: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0022 - accuracy: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0262 - accuracy: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9921 - accuracy: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0214 - accuracy: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0055 - accuracy: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0214 - accuracy: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9828 - accuracy: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0301 - accuracy: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0197 - accuracy: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9963 - accuracy: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0011 - accuracy: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0118 - accuracy: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9901 - accuracy: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0071 - accuracy: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9866 - accuracy: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0018 - accuracy: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9949 - accuracy: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9988 - accuracy: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9969 - accuracy: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9982 - accuracy: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9997 - accuracy: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9961 - accuracy: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0192 - accuracy: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9928 - accuracy: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0099 - accuracy: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9953 - accuracy: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0103 - accuracy: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9905 - accuracy: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9910 - accuracy: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0054 - accuracy: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0033 - accuracy: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0170 - accuracy: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0031 - accuracy: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9933 - accuracy: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0147 - accuracy: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9930 - accuracy: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9887 - accuracy: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0061 - accuracy: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0016 - accuracy: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0037 - accuracy: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9519 - accuracy: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0061 - accuracy: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9702 - accuracy: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0082 - accuracy: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0056 - accuracy: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9947 - accuracy: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9890 - accuracy: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9765 - accuracy: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9991 - accuracy: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9865 - accuracy: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0210 - accuracy: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0099 - accuracy: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9995 - accuracy: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0033 - accuracy: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0014 - accuracy: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0078 - accuracy: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9800 - accuracy: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0180 - accuracy: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9933 - accuracy: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9939 - accuracy: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9614 - accuracy: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9903 - accuracy: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9961 - accuracy: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9883 - accuracy: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0016 - accuracy: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9920 - accuracy: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9823 - accuracy: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0220 - accuracy: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0027 - accuracy: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0014 - accuracy: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0107 - accuracy: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0120 - accuracy: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9818 - accuracy: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9996 - accuracy: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0076 - accuracy: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0160 - accuracy: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9797 - accuracy: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0062 - accuracy: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9900 - accuracy: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9926 - accuracy: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9819 - accuracy: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0143 - accuracy: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0025 - accuracy: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9952 - accuracy: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9936 - accuracy: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0110 - accuracy: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9873 - accuracy: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0029 - accuracy: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9999 - accuracy: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9933 - accuracy: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0010 - accuracy: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9871 - accuracy: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0042 - accuracy: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0046 - accuracy: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9947 - accuracy: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0063 - accuracy: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0119 - accuracy: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9949 - accuracy: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9835 - accuracy: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0038 - accuracy: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9952 - accuracy: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0095 - accuracy: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0086 - accuracy: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9907 - accuracy: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9988 - accuracy: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9960 - accuracy: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00: 0s - loss: 169.7\n",
      "Epoch 636/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0103 - accuracy: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9830 - accuracy: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0018 - accuracy: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9891 - accuracy: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0037 - accuracy: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9828 - accuracy: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0084 - accuracy: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9987 - accuracy: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9945 - accuracy: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0093 - accuracy: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0040 - accuracy: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 182.3022 - accuracy: 0.0000e+ - 1s 2ms/step - loss: 182.0246 - accuracy: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9919 - accuracy: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9953 - accuracy: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9961 - accuracy: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9551 - accuracy: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0141 - accuracy: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0093 - accuracy: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9820 - accuracy: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9950 - accuracy: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0152 - accuracy: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9925 - accuracy: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0138 - accuracy: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9935 - accuracy: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9707 - accuracy: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0054 - accuracy: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0029 - accuracy: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9994 - accuracy: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0154 - accuracy: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9914 - accuracy: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0105 - accuracy: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9973 - accuracy: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9944 - accuracy: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9874 - accuracy: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0075 - accuracy: 0.0000e+00\n",
      "Epoch 673/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9881 - accuracy: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9987 - accuracy: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9787 - accuracy: 0.0000e+00\n",
      "Epoch 677/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0122 - accuracy: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9861 - accuracy: 0.0000e+00\n",
      "Epoch 679/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0111 - accuracy: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0148 - accuracy: 0.0000e+00\n",
      "Epoch 682/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0261 - accuracy: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0024 - accuracy: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9929 - accuracy: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9903 - accuracy: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0112 - accuracy: 0.0000e+00\n",
      "Epoch 687/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0177 - accuracy: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 690/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0122 - accuracy: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9928 - accuracy: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0017 - accuracy: 0.0000e+00\n",
      "Epoch 693/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 694/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0019 - accuracy: 0.0000e+00\n",
      "Epoch 695/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9960 - accuracy: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0126 - accuracy: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9872 - accuracy: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0087 - accuracy: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9713 - accuracy: 0.0000e+00\n",
      "Epoch 700/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0016 - accuracy: 0.0000e+00\n",
      "Epoch 701/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9796 - accuracy: 0.0000e+00\n",
      "Epoch 702/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9892 - accuracy: 0.0000e+00\n",
      "Epoch 703/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9809 - accuracy: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9889 - accuracy: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9940 - accuracy: 0.0000e+00\n",
      "Epoch 706/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 707/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9865 - accuracy: 0.0000e+00\n",
      "Epoch 708/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0078 - accuracy: 0.0000e+00\n",
      "Epoch 709/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0022 - accuracy: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0066 - accuracy: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0128 - accuracy: 0.0000e+00\n",
      "Epoch 712/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9902 - accuracy: 0.0000e+00\n",
      "Epoch 713/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0069 - accuracy: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9835 - accuracy: 0.0000e+00\n",
      "Epoch 716/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9931 - accuracy: 0.0000e+00\n",
      "Epoch 718/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9729 - accuracy: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9945 - accuracy: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9869 - accuracy: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0172 - accuracy: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9655 - accuracy: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0010 - accuracy: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9833 - accuracy: 0.0000e+00\n",
      "Epoch 726/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9700 - accuracy: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9953 - accuracy: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 729/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9870 - accuracy: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0032 - accuracy: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9870 - accuracy: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 733/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0011 - accuracy: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9965 - accuracy: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9896 - accuracy: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9845 - accuracy: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0237 - accuracy: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0170 - accuracy: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9772 - accuracy: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0045 - accuracy: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0232 - accuracy: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 744/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9903 - accuracy: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0004 - accuracy: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0143 - accuracy: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9995 - accuracy: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9881 - accuracy: 0.0000e+00\n",
      "Epoch 749/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 750/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9895 - accuracy: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0065 - accuracy: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9874 - accuracy: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9954 - accuracy: 0.0000e+00\n",
      "Epoch 755/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9977 - accuracy: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0025 - accuracy: 0.0000e+00\n",
      "Epoch 757/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9689 - accuracy: 0.0000e+00\n",
      "Epoch 758/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0105 - accuracy: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0056 - accuracy: 0.0000e+00: 0s - loss: 179.1\n",
      "Epoch 760/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9910 - accuracy: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9697 - accuracy: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9909 - accuracy: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0076 - accuracy: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9737 - accuracy: 0.0000e+00\n",
      "Epoch 766/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0041 - accuracy: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0117 - accuracy: 0.0000e+00\n",
      "Epoch 769/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 770/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9985 - accuracy: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9902 - accuracy: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0163 - accuracy: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0026 - accuracy: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9802 - accuracy: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9842 - accuracy: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0036 - accuracy: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0095 - accuracy: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9892 - accuracy: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9901 - accuracy: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0090 - accuracy: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 785/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 182.9198 - accuracy: 0.0000e+ - 1s 2ms/step - loss: 181.9984 - accuracy: 0.0000e+00\n",
      "Epoch 786/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0013 - accuracy: 0.0000e+00\n",
      "Epoch 787/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0113 - accuracy: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0075 - accuracy: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9967 - accuracy: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0206 - accuracy: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0011 - accuracy: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0115 - accuracy: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9982 - accuracy: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0100 - accuracy: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9942 - accuracy: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9872 - accuracy: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9911 - accuracy: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0040 - accuracy: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0242 - accuracy: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9957 - accuracy: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 802/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9788 - accuracy: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0178 - accuracy: 0.0000e+00\n",
      "Epoch 804/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0162 - accuracy: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0000 - accuracy: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0011 - accuracy: 0.0000e+00\n",
      "Epoch 807/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0152 - accuracy: 0.0000e+00\n",
      "Epoch 808/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9874 - accuracy: 0.0000e+00\n",
      "Epoch 809/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9843 - accuracy: 0.0000e+00\n",
      "Epoch 810/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0269 - accuracy: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9944 - accuracy: 0.0000e+00\n",
      "Epoch 812/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 813/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9949 - accuracy: 0.0000e+00\n",
      "Epoch 814/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0085 - accuracy: 0.0000e+00\n",
      "Epoch 815/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0078 - accuracy: 0.0000e+00\n",
      "Epoch 816/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0051 - accuracy: 0.0000e+00\n",
      "Epoch 817/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9918 - accuracy: 0.0000e+00: 0s - loss: 193\n",
      "Epoch 818/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9902 - accuracy: 0.0000e+00\n",
      "Epoch 819/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0094 - accuracy: 0.0000e+00\n",
      "Epoch 820/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0012 - accuracy: 0.0000e+00\n",
      "Epoch 821/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9886 - accuracy: 0.0000e+00\n",
      "Epoch 822/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9708 - accuracy: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0007 - accuracy: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0040 - accuracy: 0.0000e+00\n",
      "Epoch 826/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0028 - accuracy: 0.0000e+00\n",
      "Epoch 827/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9978 - accuracy: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 829/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0009 - accuracy: 0.0000e+00\n",
      "Epoch 830/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0211 - accuracy: 0.0000e+00\n",
      "Epoch 831/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0065 - accuracy: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9912 - accuracy: 0.0000e+00\n",
      "Epoch 833/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0227 - accuracy: 0.0000e+00\n",
      "Epoch 834/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0064 - accuracy: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0036 - accuracy: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9888 - accuracy: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9955 - accuracy: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9889 - accuracy: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9941 - accuracy: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0054 - accuracy: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9872 - accuracy: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0079 - accuracy: 0.0000e+00\n",
      "Epoch 843/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9960 - accuracy: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9939 - accuracy: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0048 - accuracy: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9989 - accuracy: 0.0000e+00\n",
      "Epoch 847/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9982 - accuracy: 0.0000e+00\n",
      "Epoch 848/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0099 - accuracy: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0113 - accuracy: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9861 - accuracy: 0.0000e+00\n",
      "Epoch 851/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9960 - accuracy: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9871 - accuracy: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9895 - accuracy: 0.0000e+00\n",
      "Epoch 854/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0097 - accuracy: 0.0000e+00\n",
      "Epoch 855/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9983 - accuracy: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9963 - accuracy: 0.0000e+00\n",
      "Epoch 857/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9949 - accuracy: 0.0000e+00\n",
      "Epoch 858/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9893 - accuracy: 0.0000e+00\n",
      "Epoch 859/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9982 - accuracy: 0.0000e+00\n",
      "Epoch 860/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0189 - accuracy: 0.0000e+00\n",
      "Epoch 861/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9891 - accuracy: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9914 - accuracy: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 864/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9780 - accuracy: 0.0000e+00\n",
      "Epoch 865/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9714 - accuracy: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0097 - accuracy: 0.0000e+00\n",
      "Epoch 867/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0123 - accuracy: 0.0000e+00\n",
      "Epoch 868/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0024 - accuracy: 0.0000e+00\n",
      "Epoch 869/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9816 - accuracy: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9975 - accuracy: 0.0000e+00\n",
      "Epoch 871/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9917 - accuracy: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9945 - accuracy: 0.0000e+00\n",
      "Epoch 873/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0049 - accuracy: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9991 - accuracy: 0.0000e+00\n",
      "Epoch 875/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0139 - accuracy: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0060 - accuracy: 0.0000e+00\n",
      "Epoch 877/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9740 - accuracy: 0.0000e+00\n",
      "Epoch 878/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9882 - accuracy: 0.0000e+00\n",
      "Epoch 879/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9921 - accuracy: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9978 - accuracy: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0187 - accuracy: 0.0000e+00\n",
      "Epoch 883/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0155 - accuracy: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9762 - accuracy: 0.0000e+00\n",
      "Epoch 885/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0065 - accuracy: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9962 - accuracy: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0017 - accuracy: 0.0000e+00\n",
      "Epoch 888/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9747 - accuracy: 0.0000e+00\n",
      "Epoch 889/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9958 - accuracy: 0.0000e+00\n",
      "Epoch 890/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9866 - accuracy: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0066 - accuracy: 0.0000e+00\n",
      "Epoch 892/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0111 - accuracy: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9837 - accuracy: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0039 - accuracy: 0.0000e+00\n",
      "Epoch 896/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 181.9937 - accuracy: 0.0000e+ - 1s 2ms/step - loss: 181.9940 - accuracy: 0.0000e+00\n",
      "Epoch 897/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9983 - accuracy: 0.0000e+00\n",
      "Epoch 898/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0068 - accuracy: 0.0000e+00\n",
      "Epoch 899/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9930 - accuracy: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0015 - accuracy: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0113 - accuracy: 0.0000e+00\n",
      "Epoch 902/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9854 - accuracy: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0116 - accuracy: 0.0000e+00: 0s - loss: 185.478\n",
      "Epoch 904/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9856 - accuracy: 0.0000e+00\n",
      "Epoch 905/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0178 - accuracy: 0.0000e+00\n",
      "Epoch 906/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0107 - accuracy: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9921 - accuracy: 0.0000e+00\n",
      "Epoch 908/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 909/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0097 - accuracy: 0.0000e+00\n",
      "Epoch 910/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0157 - accuracy: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0085 - accuracy: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9873 - accuracy: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9920 - accuracy: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9921 - accuracy: 0.0000e+00\n",
      "Epoch 915/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9888 - accuracy: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9986 - accuracy: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0071 - accuracy: 0.0000e+00\n",
      "Epoch 918/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9904 - accuracy: 0.0000e+00\n",
      "Epoch 919/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9646 - accuracy: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0033 - accuracy: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9907 - accuracy: 0.0000e+00\n",
      "Epoch 922/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0027 - accuracy: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0099 - accuracy: 0.0000e+00\n",
      "Epoch 924/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9915 - accuracy: 0.0000e+00\n",
      "Epoch 925/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0125 - accuracy: 0.0000e+00\n",
      "Epoch 926/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0250 - accuracy: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9905 - accuracy: 0.0000e+00\n",
      "Epoch 928/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9956 - accuracy: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0130 - accuracy: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9839 - accuracy: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9851 - accuracy: 0.0000e+00\n",
      "Epoch 932/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 933/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9948 - accuracy: 0.0000e+00\n",
      "Epoch 934/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9918 - accuracy: 0.0000e+00\n",
      "Epoch 935/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0143 - accuracy: 0.0000e+00\n",
      "Epoch 936/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0002 - accuracy: 0.0000e+00\n",
      "Epoch 937/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9990 - accuracy: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9867 - accuracy: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9976 - accuracy: 0.0000e+00\n",
      "Epoch 940/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0066 - accuracy: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 942/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 943/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0023 - accuracy: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9931 - accuracy: 0.0000e+00\n",
      "Epoch 946/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n",
      "Epoch 947/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0095 - accuracy: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9759 - accuracy: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0006 - accuracy: 0.0000e+00\n",
      "Epoch 950/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9849 - accuracy: 0.0000e+00\n",
      "Epoch 952/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0104 - accuracy: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9876 - accuracy: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0133 - accuracy: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9773 - accuracy: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0055 - accuracy: 0.0000e+00\n",
      "Epoch 957/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0052 - accuracy: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0064 - accuracy: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9928 - accuracy: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0018 - accuracy: 0.0000e+00\n",
      "Epoch 961/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0170 - accuracy: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9947 - accuracy: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0187 - accuracy: 0.0000e+00\n",
      "Epoch 964/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0062 - accuracy: 0.0000e+00\n",
      "Epoch 965/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9849 - accuracy: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9861 - accuracy: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9932 - accuracy: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0034 - accuracy: 0.0000e+00\n",
      "Epoch 969/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9895 - accuracy: 0.0000e+00\n",
      "Epoch 970/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9798 - accuracy: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0042 - accuracy: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0061 - accuracy: 0.0000e+00\n",
      "Epoch 973/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9936 - accuracy: 0.0000e+00: 0s - loss: 191\n",
      "Epoch 974/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9868 - accuracy: 0.0000e+00: 0s - loss: 189.030\n",
      "Epoch 975/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9964 - accuracy: 0.0000e+00\n",
      "Epoch 976/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0038 - accuracy: 0.0000e+00\n",
      "Epoch 977/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0176 - accuracy: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0103 - accuracy: 0.0000e+00\n",
      "Epoch 979/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9922 - accuracy: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0058 - accuracy: 0.0000e+00\n",
      "Epoch 981/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9787 - accuracy: 0.0000e+00\n",
      "Epoch 982/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0314 - accuracy: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0290 - accuracy: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0083 - accuracy: 0.0000e+00\n",
      "Epoch 985/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9950 - accuracy: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9918 - accuracy: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9877 - accuracy: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9920 - accuracy: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0067 - accuracy: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0067 - accuracy: 0.0000e+00\n",
      "Epoch 991/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9935 - accuracy: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9887 - accuracy: 0.0000e+00\n",
      "Epoch 993/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0005 - accuracy: 0.0000e+00\n",
      "Epoch 994/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9993 - accuracy: 0.0000e+00\n",
      "Epoch 995/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9748 - accuracy: 0.0000e+00\n",
      "Epoch 996/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9815 - accuracy: 0.0000e+00\n",
      "Epoch 997/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0075 - accuracy: 0.0000e+00\n",
      "Epoch 998/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 182.0039 - accuracy: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9836 - accuracy: 0.0000e+00\n",
      "Epoch 1000/1000\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 181.9938 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdb8b31248>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "basic_model.fit(X_train, y_train, batch_size=b_size, epochs=1000, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1639670727788,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "YRTSMKw6zJ-h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDA7B26C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDA7B26C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1, 4) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1, 4), dtype=tf.float32, name='LSTMLayer_input'), name='LSTMLayer_input', description=\"created by layer 'LSTMLayer_input'\"), but it was called on an input with incompatible shape (32, 1, 4).\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 179.9710 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[179.97096252441406, 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "aborted",
     "timestamp": 1639670727789,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Nv1MzzHR2EEX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDBC95F5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDBC95F5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (100, 1, 4) for input KerasTensor(type_spec=TensorSpec(shape=(100, 1, 4), dtype=tf.float32, name='LSTMLayer_input'), name='LSTMLayer_input', description=\"created by layer 'LSTMLayer_input'\"), but it was called on an input with incompatible shape (32, 1, 4).\n"
     ]
    }
   ],
   "source": [
    "prediction_result_basic = basic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zvu7e8Gw_lA"
   },
   "source": [
    "##Stack LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "aborted",
     "timestamp": 1639670727791,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Ww1nDKXjyu2v"
   },
   "outputs": [],
   "source": [
    "###Stack LSTM###\n",
    "s_model = Sequential()\n",
    "s_model.add(LSTM(200, activation=\"relu\", input_shape=(n_steps, n_features), return_sequences=True))\n",
    "s_model.add(LSTM(200, activation=\"relu\"))\n",
    "s_model.add(Dense(1))\n",
    "s_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "aborted",
     "timestamp": 1639670727792,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Zhu0JIagyL9i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDBDEE45E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDBDEE45E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 3s 4ms/step - loss: 187.0485 - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 181.7508 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 180.0928 - accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 178.7227 - accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 173.8240 - accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 162.1625 - accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 146.6192 - accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 135.5725 - accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 123.2553 - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 118.6952 - accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 115.7732 - accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 115.7792 - accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 113.6548 - accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 114.7897 - accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 112.0112 - accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 113.2778 - accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 111.1082 - accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 110.7907 - accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 109.7218 - accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 110.1438 - accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 108.5129 - accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 109.6189 - accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 110.0819 - accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 109.0629 - accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.0183 - accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 108.2915 - accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.6776 - accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 108.6133 - accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.3982 - accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.4065 - accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.3593 - accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.8374 - accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.6852 - accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.9677 - accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.8889 - accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.4956 - accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 107.3392 - accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.3054 - accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.6303 - accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.0600 - accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.9356 - accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.9428 - accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.5958 - accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.4993 - accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.1427 - accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.6717 - accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.6925 - accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.6931 - accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 106.1796 - accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.8358 - accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.4149 - accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.2082 - accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.3652 - accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.6865 - accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.8187 - accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.6134 - accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.3619 - accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.3433 - accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.2065 - accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 105.4294 - accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.2115 - accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.1651 - accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.7425 - accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.1167 - accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.7733 - accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.2982 - accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.6649 - accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.1931 - accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.1879 - accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.9817 - accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.4838 - accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.2755 - accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.3091 - accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.2374 - accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.8254 - accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7922 - accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.1320 - accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.3897 - accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.0663 - accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.2977 - accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7469 - accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.0745 - accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.3722 - accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 104.7710 - accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.5801 - accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.8476 - accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4271 - accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.0972 - accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.5077 - accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.9428 - accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.1284 - accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.1470 - accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.2199 - accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7522 - accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4785 - accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.9969 - accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.9878 - accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.5215 - accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.5066 - accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7192 - accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.6511 - accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4299 - accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.7163 - accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.9958 - accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4526 - accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.3678 - accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7547 - accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.6374 - accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.3692 - accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.4389 - accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.2619 - accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.3488 - accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.0156 - accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4689 - accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.2656 - accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8658 - accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.2598 - accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.6055 - accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.5547 - accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.6363 - accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.9741 - accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.2578 - accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4012 - accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.3375 - accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.7005 - accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.9910 - accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.2179 - accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8634 - accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 103.4987 - accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.0493 - accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4749 - accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.3305 - accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8347 - accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.1449 - accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.1921 - accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8137 - accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.7322 - accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.1874 - accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8499 - accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.2974 - accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.6181 - accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4408 - accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.5333 - accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8620 - accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1638 - accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.5157 - accuracy: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3502 - accuracy: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8320 - accuracy: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5373 - accuracy: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5995 - accuracy: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.5445 - accuracy: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.2943 - accuracy: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.5686 - accuracy: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8345 - accuracy: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.6888 - accuracy: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2640 - accuracy: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8712 - accuracy: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8690 - accuracy: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3182 - accuracy: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.4687 - accuracy: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.3806 - accuracy: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.8344 - accuracy: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.0587 - accuracy: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.6939 - accuracy: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.0388 - accuracy: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.5072 - accuracy: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5914 - accuracy: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.7860 - accuracy: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0357 - accuracy: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5654 - accuracy: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4762 - accuracy: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4215 - accuracy: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1181 - accuracy: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2873 - accuracy: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 102.0530 - accuracy: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.3465 - accuracy: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4137 - accuracy: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5828 - accuracy: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0860 - accuracy: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.1183 - accuracy: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3317 - accuracy: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.4858 - accuracy: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2999 - accuracy: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3592 - accuracy: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0888 - accuracy: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0224 - accuracy: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.4365 - accuracy: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3803 - accuracy: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.4050 - accuracy: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2487 - accuracy: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0961 - accuracy: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.3345 - accuracy: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1332 - accuracy: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4302 - accuracy: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.6888 - accuracy: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3872 - accuracy: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.8799 - accuracy: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3714 - accuracy: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2443 - accuracy: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.9760 - accuracy: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5089 - accuracy: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6516 - accuracy: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.5421 - accuracy: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5225 - accuracy: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.5954 - accuracy: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1752 - accuracy: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.8617 - accuracy: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1417 - accuracy: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4159 - accuracy: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 101.8601 - accuracy: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.7058 - accuracy: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.5919 - accuracy: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6305 - accuracy: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.7241 - accuracy: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.5037 - accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.5107 - accuracy: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.7613 - accuracy: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2704 - accuracy: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2197 - accuracy: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1110 - accuracy: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6183 - accuracy: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.8205 - accuracy: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3218 - accuracy: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2647 - accuracy: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.8471 - accuracy: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1053 - accuracy: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2883 - accuracy: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.9286 - accuracy: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.1785 - accuracy: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.7695 - accuracy: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2291 - accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2789 - accuracy: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0413 - accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.8677 - accuracy: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.6404 - accuracy: 0.0000e+00: 1s - loss: 97.\n",
      "Epoch 236/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.9306 - accuracy: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0324 - accuracy: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.6095 - accuracy: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5974 - accuracy: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2580 - accuracy: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.4129 - accuracy: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1193 - accuracy: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4199 - accuracy: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4007 - accuracy: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1628 - accuracy: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1630 - accuracy: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4004 - accuracy: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.2567 - accuracy: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2719 - accuracy: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.7123 - accuracy: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2203 - accuracy: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.8047 - accuracy: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6013 - accuracy: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2593 - accuracy: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.7987 - accuracy: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.9376 - accuracy: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3376 - accuracy: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7736 - accuracy: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.0993 - accuracy: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0216 - accuracy: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1156 - accuracy: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2186 - accuracy: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6296 - accuracy: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6265 - accuracy: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1358 - accuracy: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.7556 - accuracy: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.6247 - accuracy: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7569 - accuracy: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1749 - accuracy: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0667 - accuracy: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7192 - accuracy: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5838 - accuracy: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4509 - accuracy: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.9326 - accuracy: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2398 - accuracy: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.8085 - accuracy: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0783 - accuracy: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4011 - accuracy: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1912 - accuracy: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7348 - accuracy: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6967 - accuracy: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7111 - accuracy: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.8033 - accuracy: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2033 - accuracy: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2578 - accuracy: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.9399 - accuracy: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 100.3117 - accuracy: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.4385 - accuracy: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.3768 - accuracy: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7033 - accuracy: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2019 - accuracy: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.8388 - accuracy: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1077 - accuracy: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.7189 - accuracy: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2211 - accuracy: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3949 - accuracy: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7763 - accuracy: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.2311 - accuracy: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1712 - accuracy: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0666 - accuracy: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3664 - accuracy: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7434 - accuracy: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5692 - accuracy: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7450 - accuracy: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.4754 - accuracy: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0937 - accuracy: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4011 - accuracy: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.9017 - accuracy: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1273 - accuracy: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3049 - accuracy: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6866 - accuracy: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6234 - accuracy: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.9182 - accuracy: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4458 - accuracy: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5757 - accuracy: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5709 - accuracy: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0936 - accuracy: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.4812 - accuracy: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3884 - accuracy: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5009 - accuracy: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6774 - accuracy: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1234 - accuracy: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7231 - accuracy: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3260 - accuracy: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0480 - accuracy: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2660 - accuracy: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9389 - accuracy: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.3688 - accuracy: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1777 - accuracy: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9755 - accuracy: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.4867 - accuracy: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9025 - accuracy: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.4270 - accuracy: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0138 - accuracy: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9972 - accuracy: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0714 - accuracy: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6713 - accuracy: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2762 - accuracy: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1255 - accuracy: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8132 - accuracy: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5910 - accuracy: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1902 - accuracy: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1112 - accuracy: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6745 - accuracy: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2846 - accuracy: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0660 - accuracy: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9909 - accuracy: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2961 - accuracy: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8442 - accuracy: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5259 - accuracy: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3803 - accuracy: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6904 - accuracy: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7968 - accuracy: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.3041 - accuracy: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6444 - accuracy: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2602 - accuracy: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9321 - accuracy: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1374 - accuracy: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.8350 - accuracy: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0809 - accuracy: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3392 - accuracy: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.0340 - accuracy: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2374 - accuracy: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7437 - accuracy: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0293 - accuracy: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7980 - accuracy: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5680 - accuracy: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9055 - accuracy: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6337 - accuracy: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1303 - accuracy: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1625 - accuracy: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1607 - accuracy: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5944 - accuracy: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6481 - accuracy: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.6115 - accuracy: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1789 - accuracy: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7380 - accuracy: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9274 - accuracy: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3461 - accuracy: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6148 - accuracy: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5321 - accuracy: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5795 - accuracy: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1599 - accuracy: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5985 - accuracy: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.1403 - accuracy: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.2791 - accuracy: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7585 - accuracy: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2354 - accuracy: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0747 - accuracy: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4136 - accuracy: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1633 - accuracy: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8690 - accuracy: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.7129 - accuracy: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.4335 - accuracy: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.1612 - accuracy: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7623 - accuracy: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4067 - accuracy: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4899 - accuracy: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.8144 - accuracy: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8503 - accuracy: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 97.7772 - accuracy: 0.0000e+0 - 1s 4ms/step - loss: 97.7638 - accuracy: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7289 - accuracy: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0867 - accuracy: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8095 - accuracy: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8358 - accuracy: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3533 - accuracy: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.1305 - accuracy: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4150 - accuracy: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4328 - accuracy: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.5627 - accuracy: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9150 - accuracy: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2118 - accuracy: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3428 - accuracy: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1599 - accuracy: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5365 - accuracy: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0143 - accuracy: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3385 - accuracy: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1798 - accuracy: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.9930 - accuracy: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5025 - accuracy: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4831 - accuracy: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3170 - accuracy: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5972 - accuracy: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.8566 - accuracy: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4322 - accuracy: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8282 - accuracy: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3047 - accuracy: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2560 - accuracy: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7672 - accuracy: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.8909 - accuracy: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.7960 - accuracy: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5892 - accuracy: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5395 - accuracy: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1535 - accuracy: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1099 - accuracy: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.8664 - accuracy: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6703 - accuracy: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.1235 - accuracy: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6857 - accuracy: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.5319 - accuracy: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6062 - accuracy: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3212 - accuracy: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2476 - accuracy: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2924 - accuracy: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3659 - accuracy: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4574 - accuracy: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2675 - accuracy: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.2510 - accuracy: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 99.1753 - accuracy: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0926 - accuracy: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3794 - accuracy: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.3383 - accuracy: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.1867 - accuracy: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0843 - accuracy: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0981 - accuracy: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0868 - accuracy: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7194 - accuracy: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.0674 - accuracy: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.7979 - accuracy: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.0452 - accuracy: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 98.1588 - accuracy: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.4002 - accuracy: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 97.6673 - accuracy: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6629 - accuracy: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.7922 - accuracy: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3611 - accuracy: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.9621 - accuracy: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.5962 - accuracy: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.8551 - accuracy: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.8193 - accuracy: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6555 - accuracy: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3898 - accuracy: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.5532 - accuracy: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3033 - accuracy: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4535 - accuracy: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4689 - accuracy: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6499 - accuracy: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4989 - accuracy: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3196 - accuracy: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4653 - accuracy: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6239 - accuracy: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1326 - accuracy: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.7998 - accuracy: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9022 - accuracy: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3300 - accuracy: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1712 - accuracy: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8690 - accuracy: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5881 - accuracy: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4331 - accuracy: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.2918 - accuracy: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.6899 - accuracy: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.2753 - accuracy: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4402 - accuracy: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9364 - accuracy: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0209 - accuracy: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4630 - accuracy: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.2925 - accuracy: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.7320 - accuracy: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8293 - accuracy: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2932 - accuracy: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3184 - accuracy: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4686 - accuracy: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3675 - accuracy: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0119 - accuracy: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7740 - accuracy: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3677 - accuracy: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3879 - accuracy: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9194 - accuracy: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.6480 - accuracy: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9432 - accuracy: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7526 - accuracy: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5796 - accuracy: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0630 - accuracy: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.6841 - accuracy: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9939 - accuracy: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0527 - accuracy: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4884 - accuracy: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8419 - accuracy: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0282 - accuracy: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2700 - accuracy: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9078 - accuracy: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.6586 - accuracy: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3227 - accuracy: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2743 - accuracy: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9708 - accuracy: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2823 - accuracy: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.2924 - accuracy: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0329 - accuracy: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7740 - accuracy: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3693 - accuracy: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9395 - accuracy: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1002 - accuracy: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7048 - accuracy: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4931 - accuracy: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3061 - accuracy: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4064 - accuracy: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4292 - accuracy: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3356 - accuracy: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8253 - accuracy: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8650 - accuracy: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.6946 - accuracy: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9874 - accuracy: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3320 - accuracy: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9627 - accuracy: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8428 - accuracy: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7562 - accuracy: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3554 - accuracy: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.9484 - accuracy: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8972 - accuracy: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4850 - accuracy: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.8353 - accuracy: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3080 - accuracy: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.6158 - accuracy: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7653 - accuracy: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5681 - accuracy: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7729 - accuracy: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5049 - accuracy: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5300 - accuracy: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4176 - accuracy: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2858 - accuracy: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4982 - accuracy: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0812 - accuracy: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3399 - accuracy: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0802 - accuracy: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.4323 - accuracy: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0793 - accuracy: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7711 - accuracy: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3327 - accuracy: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3038 - accuracy: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2638 - accuracy: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8838 - accuracy: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2970 - accuracy: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0708 - accuracy: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1327 - accuracy: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.3950 - accuracy: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4419 - accuracy: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9944 - accuracy: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5164 - accuracy: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4956 - accuracy: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7782 - accuracy: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4388 - accuracy: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8490 - accuracy: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7339 - accuracy: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7151 - accuracy: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3273 - accuracy: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5571 - accuracy: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1739 - accuracy: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0682 - accuracy: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6722 - accuracy: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9034 - accuracy: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1492 - accuracy: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2036 - accuracy: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4990 - accuracy: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6271 - accuracy: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4383 - accuracy: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2826 - accuracy: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8500 - accuracy: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4260 - accuracy: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1752 - accuracy: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0208 - accuracy: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9213 - accuracy: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0909 - accuracy: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5179 - accuracy: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7137 - accuracy: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1028 - accuracy: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5708 - accuracy: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8761 - accuracy: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1524 - accuracy: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.0827 - accuracy: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0734 - accuracy: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1546 - accuracy: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0259 - accuracy: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5676 - accuracy: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2079 - accuracy: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4307 - accuracy: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8472 - accuracy: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1192 - accuracy: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0018 - accuracy: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2392 - accuracy: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1172 - accuracy: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0952 - accuracy: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3541 - accuracy: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4736 - accuracy: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5194 - accuracy: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1972 - accuracy: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8652 - accuracy: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6704 - accuracy: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5574 - accuracy: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9572 - accuracy: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7892 - accuracy: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7851 - accuracy: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4848 - accuracy: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1137 - accuracy: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2659 - accuracy: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1049 - accuracy: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2253 - accuracy: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9473 - accuracy: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6986 - accuracy: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2425 - accuracy: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8908 - accuracy: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2280 - accuracy: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8915 - accuracy: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3956 - accuracy: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0475 - accuracy: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7582 - accuracy: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3612 - accuracy: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1323 - accuracy: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9236 - accuracy: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 96.1510 - accuracy: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1172 - accuracy: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0073 - accuracy: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9579 - accuracy: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9814 - accuracy: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1411 - accuracy: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7341 - accuracy: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0145 - accuracy: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5828 - accuracy: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5304 - accuracy: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5935 - accuracy: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0528 - accuracy: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4788 - accuracy: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6562 - accuracy: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2937 - accuracy: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8400 - accuracy: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6229 - accuracy: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7306 - accuracy: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9943 - accuracy: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1907 - accuracy: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7986 - accuracy: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2269 - accuracy: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0322 - accuracy: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7056 - accuracy: 0.0000e+00\n",
      "Epoch 673/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6667 - accuracy: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8908 - accuracy: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6678 - accuracy: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2533 - accuracy: 0.0000e+00\n",
      "Epoch 677/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3384 - accuracy: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6825 - accuracy: 0.0000e+00\n",
      "Epoch 679/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4480 - accuracy: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9552 - accuracy: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8950 - accuracy: 0.0000e+00\n",
      "Epoch 682/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7463 - accuracy: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5732 - accuracy: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7663 - accuracy: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1815 - accuracy: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8081 - accuracy: 0.0000e+00\n",
      "Epoch 687/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4040 - accuracy: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5016 - accuracy: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7603 - accuracy: 0.0000e+00\n",
      "Epoch 690/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.5368 - accuracy: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0724 - accuracy: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7069 - accuracy: 0.0000e+00\n",
      "Epoch 693/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8037 - accuracy: 0.0000e+00\n",
      "Epoch 694/1000\n",
      "321/321 [==============================] - ETA: 0s - loss: 95.6247 - accuracy: 0.0000e+0 - 1s 4ms/step - loss: 95.2226 - accuracy: 0.0000e+00\n",
      "Epoch 695/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2483 - accuracy: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7215 - accuracy: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1907 - accuracy: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0060 - accuracy: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5598 - accuracy: 0.0000e+00\n",
      "Epoch 700/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1040 - accuracy: 0.0000e+00\n",
      "Epoch 701/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4711 - accuracy: 0.0000e+00\n",
      "Epoch 702/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8985 - accuracy: 0.0000e+00\n",
      "Epoch 703/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7078 - accuracy: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0034 - accuracy: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5044 - accuracy: 0.0000e+00\n",
      "Epoch 706/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4709 - accuracy: 0.0000e+00\n",
      "Epoch 707/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3270 - accuracy: 0.0000e+00\n",
      "Epoch 708/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9627 - accuracy: 0.0000e+00\n",
      "Epoch 709/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7155 - accuracy: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2723 - accuracy: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7683 - accuracy: 0.0000e+00\n",
      "Epoch 712/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5680 - accuracy: 0.0000e+00\n",
      "Epoch 713/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9796 - accuracy: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9947 - accuracy: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4835 - accuracy: 0.0000e+00\n",
      "Epoch 716/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9211 - accuracy: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6570 - accuracy: 0.0000e+00\n",
      "Epoch 718/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7782 - accuracy: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3602 - accuracy: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6801 - accuracy: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2141 - accuracy: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7679 - accuracy: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6676 - accuracy: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4109 - accuracy: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4987 - accuracy: 0.0000e+00\n",
      "Epoch 726/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5745 - accuracy: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8362 - accuracy: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8441 - accuracy: 0.0000e+00\n",
      "Epoch 729/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3833 - accuracy: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3454 - accuracy: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5423 - accuracy: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4598 - accuracy: 0.0000e+00\n",
      "Epoch 733/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6365 - accuracy: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5226 - accuracy: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8115 - accuracy: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6887 - accuracy: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4331 - accuracy: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4031 - accuracy: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3586 - accuracy: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4334 - accuracy: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5063 - accuracy: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2215 - accuracy: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9448 - accuracy: 0.0000e+00\n",
      "Epoch 744/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3222 - accuracy: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1298 - accuracy: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1603 - accuracy: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2567 - accuracy: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2671 - accuracy: 0.0000e+00\n",
      "Epoch 749/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1165 - accuracy: 0.0000e+00\n",
      "Epoch 750/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2854 - accuracy: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7761 - accuracy: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4219 - accuracy: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8532 - accuracy: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4454 - accuracy: 0.0000e+00\n",
      "Epoch 755/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7263 - accuracy: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1712 - accuracy: 0.0000e+00\n",
      "Epoch 757/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7565 - accuracy: 0.0000e+00\n",
      "Epoch 758/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6335 - accuracy: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1322 - accuracy: 0.0000e+00\n",
      "Epoch 760/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7465 - accuracy: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5039 - accuracy: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0040 - accuracy: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0077 - accuracy: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8518 - accuracy: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9387 - accuracy: 0.0000e+00\n",
      "Epoch 766/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5664 - accuracy: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0448 - accuracy: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5145 - accuracy: 0.0000e+00\n",
      "Epoch 769/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0895 - accuracy: 0.0000e+00\n",
      "Epoch 770/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8127 - accuracy: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6523 - accuracy: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2385 - accuracy: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2173 - accuracy: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0143 - accuracy: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6015 - accuracy: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7043 - accuracy: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5908 - accuracy: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1811 - accuracy: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8330 - accuracy: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6928 - accuracy: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3910 - accuracy: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1625 - accuracy: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2610 - accuracy: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5762 - accuracy: 0.0000e+00\n",
      "Epoch 785/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4987 - accuracy: 0.0000e+00\n",
      "Epoch 786/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1798 - accuracy: 0.0000e+00\n",
      "Epoch 787/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0786 - accuracy: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9361 - accuracy: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4012 - accuracy: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7836 - accuracy: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8029 - accuracy: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3753 - accuracy: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3296 - accuracy: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7720 - accuracy: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3923 - accuracy: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5585 - accuracy: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7151 - accuracy: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6562 - accuracy: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0313 - accuracy: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6932 - accuracy: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9067 - accuracy: 0.0000e+00\n",
      "Epoch 802/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7995 - accuracy: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0999 - accuracy: 0.0000e+00\n",
      "Epoch 804/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7476 - accuracy: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2374 - accuracy: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5123 - accuracy: 0.0000e+00\n",
      "Epoch 807/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4630 - accuracy: 0.0000e+00\n",
      "Epoch 808/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7748 - accuracy: 0.0000e+00\n",
      "Epoch 809/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0099 - accuracy: 0.0000e+00\n",
      "Epoch 810/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6369 - accuracy: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2970 - accuracy: 0.0000e+00\n",
      "Epoch 812/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3175 - accuracy: 0.0000e+00\n",
      "Epoch 813/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8004 - accuracy: 0.0000e+00\n",
      "Epoch 814/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3180 - accuracy: 0.0000e+00\n",
      "Epoch 815/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3808 - accuracy: 0.0000e+00\n",
      "Epoch 816/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8462 - accuracy: 0.0000e+00\n",
      "Epoch 817/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6358 - accuracy: 0.0000e+00\n",
      "Epoch 818/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2215 - accuracy: 0.0000e+00\n",
      "Epoch 819/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5233 - accuracy: 0.0000e+00\n",
      "Epoch 820/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7379 - accuracy: 0.0000e+00\n",
      "Epoch 821/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6677 - accuracy: 0.0000e+00\n",
      "Epoch 822/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7599 - accuracy: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4937 - accuracy: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1544 - accuracy: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.3833 - accuracy: 0.0000e+00\n",
      "Epoch 826/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9820 - accuracy: 0.0000e+00\n",
      "Epoch 827/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7427 - accuracy: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1213 - accuracy: 0.0000e+00\n",
      "Epoch 829/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4363 - accuracy: 0.0000e+00\n",
      "Epoch 830/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6643 - accuracy: 0.0000e+00\n",
      "Epoch 831/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.6208 - accuracy: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9989 - accuracy: 0.0000e+00\n",
      "Epoch 833/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7600 - accuracy: 0.0000e+00\n",
      "Epoch 834/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3705 - accuracy: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4469 - accuracy: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9895 - accuracy: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9118 - accuracy: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0092 - accuracy: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0386 - accuracy: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4320 - accuracy: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4705 - accuracy: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6724 - accuracy: 0.0000e+00\n",
      "Epoch 843/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8591 - accuracy: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.7998 - accuracy: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0345 - accuracy: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6392 - accuracy: 0.0000e+00\n",
      "Epoch 847/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8083 - accuracy: 0.0000e+00\n",
      "Epoch 848/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5538 - accuracy: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8416 - accuracy: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0956 - accuracy: 0.0000e+00\n",
      "Epoch 851/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7084 - accuracy: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9745 - accuracy: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1961 - accuracy: 0.0000e+00\n",
      "Epoch 854/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2095 - accuracy: 0.0000e+00\n",
      "Epoch 855/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4918 - accuracy: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3402 - accuracy: 0.0000e+00\n",
      "Epoch 857/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0259 - accuracy: 0.0000e+00\n",
      "Epoch 858/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4015 - accuracy: 0.0000e+00\n",
      "Epoch 859/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5050 - accuracy: 0.0000e+00\n",
      "Epoch 860/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6557 - accuracy: 0.0000e+00\n",
      "Epoch 861/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9035 - accuracy: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0501 - accuracy: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5375 - accuracy: 0.0000e+00\n",
      "Epoch 864/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3233 - accuracy: 0.0000e+00\n",
      "Epoch 865/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2783 - accuracy: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4307 - accuracy: 0.0000e+00\n",
      "Epoch 867/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5557 - accuracy: 0.0000e+00\n",
      "Epoch 868/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2448 - accuracy: 0.0000e+00\n",
      "Epoch 869/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3692 - accuracy: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1436 - accuracy: 0.0000e+00\n",
      "Epoch 871/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8824 - accuracy: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9265 - accuracy: 0.0000e+00\n",
      "Epoch 873/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1223 - accuracy: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9136 - accuracy: 0.0000e+00\n",
      "Epoch 875/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9566 - accuracy: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6907 - accuracy: 0.0000e+00\n",
      "Epoch 877/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4029 - accuracy: 0.0000e+00\n",
      "Epoch 878/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7933 - accuracy: 0.0000e+00\n",
      "Epoch 879/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.6137 - accuracy: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0803 - accuracy: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5060 - accuracy: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9915 - accuracy: 0.0000e+00\n",
      "Epoch 883/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3649 - accuracy: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1890 - accuracy: 0.0000e+00\n",
      "Epoch 885/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4318 - accuracy: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8092 - accuracy: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4610 - accuracy: 0.0000e+00\n",
      "Epoch 888/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1658 - accuracy: 0.0000e+00\n",
      "Epoch 889/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7358 - accuracy: 0.0000e+00\n",
      "Epoch 890/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0867 - accuracy: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0487 - accuracy: 0.0000e+00\n",
      "Epoch 892/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1666 - accuracy: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6877 - accuracy: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3705 - accuracy: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.5998 - accuracy: 0.0000e+00\n",
      "Epoch 896/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6854 - accuracy: 0.0000e+00\n",
      "Epoch 897/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1177 - accuracy: 0.0000e+00\n",
      "Epoch 898/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.3012 - accuracy: 0.0000e+00\n",
      "Epoch 899/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0509 - accuracy: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0002 - accuracy: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2557 - accuracy: 0.0000e+00\n",
      "Epoch 902/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0392 - accuracy: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8175 - accuracy: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.4255 - accuracy: 0.0000e+00\n",
      "Epoch 905/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3207 - accuracy: 0.0000e+00\n",
      "Epoch 906/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3121 - accuracy: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8315 - accuracy: 0.0000e+00\n",
      "Epoch 908/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0089 - accuracy: 0.0000e+00\n",
      "Epoch 909/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3720 - accuracy: 0.0000e+00\n",
      "Epoch 910/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2257 - accuracy: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4377 - accuracy: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3488 - accuracy: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4891 - accuracy: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4955 - accuracy: 0.0000e+00\n",
      "Epoch 915/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3587 - accuracy: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8585 - accuracy: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4691 - accuracy: 0.0000e+00\n",
      "Epoch 918/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0042 - accuracy: 0.0000e+00\n",
      "Epoch 919/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0800 - accuracy: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1304 - accuracy: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1354 - accuracy: 0.0000e+00\n",
      "Epoch 922/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7890 - accuracy: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6561 - accuracy: 0.0000e+00\n",
      "Epoch 924/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2201 - accuracy: 0.0000e+00\n",
      "Epoch 925/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7503 - accuracy: 0.0000e+00\n",
      "Epoch 926/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0731 - accuracy: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2857 - accuracy: 0.0000e+00\n",
      "Epoch 928/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3633 - accuracy: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8305 - accuracy: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8042 - accuracy: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2410 - accuracy: 0.0000e+00\n",
      "Epoch 932/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9488 - accuracy: 0.0000e+00\n",
      "Epoch 933/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2276 - accuracy: 0.0000e+00\n",
      "Epoch 934/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.2496 - accuracy: 0.0000e+00\n",
      "Epoch 935/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2196 - accuracy: 0.0000e+00\n",
      "Epoch 936/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4900 - accuracy: 0.0000e+00\n",
      "Epoch 937/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0881 - accuracy: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4672 - accuracy: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0791 - accuracy: 0.0000e+00\n",
      "Epoch 940/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3349 - accuracy: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.0615 - accuracy: 0.0000e+00\n",
      "Epoch 942/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.6468 - accuracy: 0.0000e+00\n",
      "Epoch 943/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3100 - accuracy: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6009 - accuracy: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.6162 - accuracy: 0.0000e+00\n",
      "Epoch 946/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7858 - accuracy: 0.0000e+00\n",
      "Epoch 947/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7297 - accuracy: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3139 - accuracy: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.4111 - accuracy: 0.0000e+00\n",
      "Epoch 950/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2774 - accuracy: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8580 - accuracy: 0.0000e+00\n",
      "Epoch 952/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4403 - accuracy: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9384 - accuracy: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.3463 - accuracy: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7183 - accuracy: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.8397 - accuracy: 0.0000e+00\n",
      "Epoch 957/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1144 - accuracy: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2525 - accuracy: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4202 - accuracy: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1277 - accuracy: 0.0000e+00\n",
      "Epoch 961/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9783 - accuracy: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9257 - accuracy: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8917 - accuracy: 0.0000e+00\n",
      "Epoch 964/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8214 - accuracy: 0.0000e+00\n",
      "Epoch 965/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 95.1670 - accuracy: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7500 - accuracy: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.7077 - accuracy: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9167 - accuracy: 0.0000e+00\n",
      "Epoch 969/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1252 - accuracy: 0.0000e+00\n",
      "Epoch 970/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2499 - accuracy: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7155 - accuracy: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2642 - accuracy: 0.0000e+00\n",
      "Epoch 973/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2059 - accuracy: 0.0000e+00\n",
      "Epoch 974/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4819 - accuracy: 0.0000e+00\n",
      "Epoch 975/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7009 - accuracy: 0.0000e+00\n",
      "Epoch 976/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0509 - accuracy: 0.0000e+00\n",
      "Epoch 977/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9977 - accuracy: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1210 - accuracy: 0.0000e+00\n",
      "Epoch 979/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1383 - accuracy: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9921 - accuracy: 0.0000e+00\n",
      "Epoch 981/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9822 - accuracy: 0.0000e+00\n",
      "Epoch 982/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8524 - accuracy: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2842 - accuracy: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2855 - accuracy: 0.0000e+00\n",
      "Epoch 985/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2077 - accuracy: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.9648 - accuracy: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.9657 - accuracy: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.6336 - accuracy: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.4061 - accuracy: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8466 - accuracy: 0.0000e+00\n",
      "Epoch 991/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0629 - accuracy: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1401 - accuracy: 0.0000e+00\n",
      "Epoch 993/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5558 - accuracy: 0.0000e+00\n",
      "Epoch 994/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.1633 - accuracy: 0.0000e+00\n",
      "Epoch 995/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.2355 - accuracy: 0.0000e+00\n",
      "Epoch 996/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.0158 - accuracy: 0.0000e+00\n",
      "Epoch 997/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.6005 - accuracy: 0.0000e+00\n",
      "Epoch 998/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 94.5938 - accuracy: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.7436 - accuracy: 0.0000e+00\n",
      "Epoch 1000/1000\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 93.8229 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdbdf7d9c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "s_model.fit(X_train, y_train, batch_size=b_size, epochs=1000, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "aborted",
     "timestamp": 1639670727792,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "fpuzZF1QzNsU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC1BE8558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC1BE8558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 89.7030 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[89.70299530029297, 0.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1639670727793,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "MWM6G8c-2LnU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC1E79798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC1E79798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_result_stack = s_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shnsSGYnxElm"
   },
   "source": [
    "##Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1639670727794,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "fzi6z7EAX9DH"
   },
   "outputs": [],
   "source": [
    "###Vanilla LSTM###\n",
    "vmodel = Sequential()\n",
    "vmodel.add(LSTM(200, activation=\"relu\", input_shape=(n_steps, n_features)))\n",
    "vmodel.add(Dense(1))\n",
    "vmodel.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1639670727794,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "7WNSM9-lyNeT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC2162D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC2162D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 211.3896 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 180.6093 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.6346 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.1243 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.5580 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 180.2319 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.1223 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.3871 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.6134 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.6498 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.3192 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.0291 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.9915 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.4588 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.1987 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.0851 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 179.5463 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 180.2504 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.0952 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.2859 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.8374 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.9176 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.2096 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.5827 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.4773 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.5797 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.3385 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.2017 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.7910 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.8319 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 177.6530 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.2283 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 177.5546 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 177.6289 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.4014 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 178.0143 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 176.9972 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 176.1714 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 173.5827 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 168.7745 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 162.5735 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 156.1801 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 149.2867 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 141.5632 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 131.3069 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 124.4593 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 118.3527 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 115.1790 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 113.2741 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 112.8904 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 110.4291 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 110.9450 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 109.8536 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 109.6765 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 109.6356 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.9781 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.5638 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1885 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.9530 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.6953 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1531 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1936 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.5440 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.5198 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.8279 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.6406 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.3797 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.3680 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.2341 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7070 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.4054 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.4920 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7565 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.6314 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1705 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.7836 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.0887 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1879 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.6395 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.5429 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.4151 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.5289 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1818 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7906 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.2371 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.2557 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.6876 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7129 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7197 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.2806 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.0377 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.7580 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 106.9724 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.3393 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.1180 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.1535 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.2679 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.1362 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 108.5173 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 107.3091 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdc21abc08>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "vmodel.fit(X_train, y_train, batch_size=b_size, epochs=100, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "aborted",
     "timestamp": 1639670727795,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "5hWEkdPYzOMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC398C558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC398C558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 106.1687 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[106.16873931884766, 0.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmodel.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "aborted",
     "timestamp": 1639670727795,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "yIkhQaz52VzW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC3A29D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC3A29D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_result_vanilla = vmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MO4NVTYxI3g"
   },
   "source": [
    "##Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1639670727796,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "X1XsH0JWb3yA"
   },
   "outputs": [],
   "source": [
    "###Bidirectional LSTM###\n",
    "bi_model = Sequential()\n",
    "bi_model.add(Bidirectional(LSTM(200, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "bi_model.add(Dense(1))\n",
    "bi_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1639670727796,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "rm2yBWAVyPVL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC1E79A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC1E79A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 2s 3ms/step - loss: 202.3356 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.2488 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 180.4203 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 179.9719 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 180.1480 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 180.1583 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 179.3432 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.4869 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 180.4538 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 179.3343 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 179.3849 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.6634 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 179.0078 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.7447 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.7642 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.6127 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.7232 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.0081 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.5788 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.6245 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.3601 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.6005 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.1451 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.8521 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.9847 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.3532 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.5246 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.4508 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.7423 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.7043 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.6749 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 176.8697 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 176.8399 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 178.0927 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.4466 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.1398 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 177.2743 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 176.0783 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 173.4379 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 167.3778 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 159.8004 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 152.7312 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 145.6792 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 136.0663 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 128.5657 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 121.8957 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 117.9374 - accuracy: 0.0000e+00: 0s - l\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 114.2685 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 112.4765 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 112.1911 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 109.7852 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 110.8172 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 109.4907 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 110.0534 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 109.3895 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.5896 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 109.1727 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.9976 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.3418 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.3004 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.5283 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1149 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.5562 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.6536 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.4310 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.8900 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.8427 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.8162 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1942 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.6071 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.8588 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.2851 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1617 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.3900 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.8365 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.3284 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.4166 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.7880 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.4186 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.3941 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.5825 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.3193 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1695 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.7600 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.0775 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1845 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.2620 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.6503 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.4549 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.6579 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.8398 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.7607 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.7788 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.0447 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.9918 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.7363 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 108.1420 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.6879 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.4086 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 107.5906 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdc20f33c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "bi_model.fit(X_train, y_train, batch_size=b_size, epochs=100, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1639670727797,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "kRGuGVxczOmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC6900828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC6900828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 102.1035 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[102.10352325439453, 0.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1639670727797,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "PEd7ii4c2ghq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC7BF2678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDC7BF2678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_result_bidirection = bi_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4ug8x6IxPDF"
   },
   "source": [
    "##LSTM with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1639670727798,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "M9pAr21Lk6qE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-self-attention in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (0.50.0)\n",
      "Requirement already satisfied: Keras in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from keras-self-attention) (2.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from keras-self-attention) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1639670727798,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "9sJkiYp_k8XU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attention in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (4.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from attention) (1.19.5)\n",
      "Requirement already satisfied: tensorflow>=2.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from attention) (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (0.36.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.36.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (12.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (0.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorflow>=2.1->attention) (3.15.6)\n",
      "Requirement already satisfied: cached-property in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from h5py>=2.9.0->tensorflow>=2.1->attention) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.28.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.16.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1->attention) (3.10.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\moonn\\miniconda3\\envs\\am_keras_tf\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1->attention) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1639670727799,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "iVQGyKWLyHPe"
   },
   "outputs": [],
   "source": [
    "\n",
    "###Worst one right now###\n",
    "from attention import Attention\n",
    "###LSTM with Attention###\n",
    "atmodel = tf.keras.models.Sequential()\n",
    "atmodel.add(tf.keras.layers.LSTM(200, input_shape=(n_steps, n_features),\n",
    "                    return_sequences=True))\n",
    "atmodel.add(Attention(name='attention_weight'))\n",
    "atmodel.add(tf.keras.layers.Dense(1, activation='relu'))\n",
    "atmodel.compile(loss='mse', optimizer='adam', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1639670727799,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "FPGADhAAyQrR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC81A7948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDC81A7948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 3s 3ms/step - loss: 211.2561 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9738 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0296 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0261 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0641 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0266 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0485 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0027 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9761 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1021 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0323 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0450 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0473 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0276 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0566 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0871 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0605 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0532 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0411 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0585 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0152 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0339 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9995 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0783 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0728 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0822 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1094 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0124 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1154 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0464 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9844 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0666 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0569 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0585 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9937 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0237 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0335 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0210 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0373 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0344 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0415 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0727 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0903 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0085 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0879 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0639 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0482 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0193 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0706 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0800 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0982 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0491 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9913 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 181.9980 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0845 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0721 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0379 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0927 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0339 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0703 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0904 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0385 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0565 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0508 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0514 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0359 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1076 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0654 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0652 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0897 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0305 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1076 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0375 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0730 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0545 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0482 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0612 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0749 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0806 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0412 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0617 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0712 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0003 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0969 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.1093 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0886 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0850 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0154 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0574 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0269 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0508 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0497 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0619 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0056 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0784 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0527 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0636 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0489 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0548 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 182.0379 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdc81fab08>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "atmodel.fit(X_train, y_train, batch_size=b_size, epochs=100, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1639670727799,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "5WgLGvqnzPBM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC81E3CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDC81E3CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 179.8636 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[179.8635711669922, 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atmodel.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1639670727800,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Jr_NYoAG2nrN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDCAD6CCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDCAD6CCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_result_attention = atmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex_LnTfvxTle"
   },
   "source": [
    "##GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1639670727800,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "GBzbmAqmw5Kv"
   },
   "outputs": [],
   "source": [
    "###GRU###Bad model\n",
    "from keras.layers import GRU\n",
    "\n",
    "gmodel = Sequential()\n",
    "gmodel.add(GRU(200, input_shape = (n_steps, n_features), return_sequences = True))\n",
    "gmodel.add(GRU(1, return_sequences = False))\n",
    "gmodel.add(Activation('relu'))  \n",
    "gmodel.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "aborted",
     "timestamp": 1639670727801,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "Bip28tpZDvDK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDCC9FB558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BDCC9FB558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "321/321 [==============================] - 3s 3ms/step - loss: 705.6749 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1420 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1270 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1218 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1198 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1182 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1176 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1170 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1165 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1165 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1160 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1160 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1158 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1156 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1156 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1156 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1148 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1157 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1157 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1148 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1157 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1157 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1158 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1156 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1157 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1158 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1149 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1154 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1151 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1156 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1155 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1152 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 705.1150 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdcca2a6c8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"loli_loli_loli_trained_for_epochs.hdf5\";\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, save_best_only=True, mode='min')\n",
    "gmodel.fit(X_train, y_train, batch_size=b_size, epochs=100, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1639670727802,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "9PqDJXn0zPlY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDCF94BAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001BDCF94BAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 687.8481 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[687.8480834960938, 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1639670727802,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "tv2LgYac2tw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDD0F2E708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001BDD0F2E708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_result_gru = gmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moNx5hQjHJKk"
   },
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1639670727803,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "ewA8QR-Ov3Ll"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import figure\n",
    "plt.plot(y_test[0:100], label= \"Actual Data\")\n",
    "plt.plot(prediction_result_basic[0:100], label=\"LSTM\",linestyle=\"--\")\n",
    "plt.plot(prediction_result_stack[0:100], label=\"Stack LSTM\",linestyle=\"--\")\n",
    "plt.plot(prediction_result_vanilla[0:100], label=\"Vanilla LSTM\",linestyle=\"--\")\n",
    "plt.plot(prediction_result_bidirection[0:100], label=\"Bidirectional LSTM\",linestyle=\"--\")\n",
    "plt.plot(prediction_result_attention[0:100], label=\"LSTM with Attention\",linestyle=\"--\")\n",
    "plt.plot(prediction_result_gru[0:100], label=\"GRU\",linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test[0:100], label= \"Actual Data\")\n",
    "plt.plot(prediction_result_stack[0:100], label=\"Stack LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1639670727803,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "6VT4lCqEJTT3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction_result = model.predict(X_test)'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"prediction_result = model.predict(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1639670727804,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "KbcSAa_IJd1n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [33.198082] Actual Ans: 52.9\n",
      "Prediction: [21.788681] Actual Ans: 20.0\n",
      "Prediction: [30.769682] Actual Ans: 46.0\n",
      "Prediction: [15.525146] Actual Ans: 11.0\n",
      "Prediction: [15.033403] Actual Ans: 12.0\n",
      "Prediction: [18.140076] Actual Ans: 17.9\n",
      "Prediction: [35.139824] Actual Ans: 81.1\n",
      "Prediction: [14.834356] Actual Ans: 15.0\n",
      "Prediction: [29.16824] Actual Ans: 26.7\n",
      "Prediction: [40.383476] Actual Ans: 56.8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(f\"Prediction: {prediction_result_stack[i]} Actual Ans: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1639670727804,
     "user": {
      "displayName": "Lunar DarkKnight",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjlTVDZaQee9Qj3QfPnsuELEYT1LGvrjYVqfli1=s64",
      "userId": "13454818571377593434"
     },
     "user_tz": -420
    },
    "id": "F8JRjF23NLVI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import sklearn.metrics as metrics\\nfrom sklearn.metrics import mean_squared_error\\n\\nmae = metrics.mean_absolute_error(y_test, prediction_result)\\nrms = mean_squared_error(y_test, prediction_result, squared=False)\\nmse = mean_squared_error(y_test, prediction_result)\\nr2 = metrics.r2_score(y_test, prediction_result)\\n\\nprint(f\"MAE:{mae}\")\\nprint(f\"MSE:{mse}\")\\nprint(f\"RMSE:{rms}\")\\nprint(f\"R-Squared:{r2}\")'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test, prediction_result)\n",
    "rms = mean_squared_error(y_test, prediction_result, squared=False)\n",
    "mse = mean_squared_error(y_test, prediction_result)\n",
    "r2 = metrics.r2_score(y_test, prediction_result)\n",
    "\n",
    "print(f\"MAE:{mae}\")\n",
    "print(f\"MSE:{mse}\")\n",
    "print(f\"RMSE:{rms}\")\n",
    "print(f\"R-Squared:{r2}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgxq6VTjU73UAREpXknP84",
   "name": "PM2.5Comparison.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
